{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","output_embedded_package_id":"1WUTTF0GlfEUUBNnL0otGIV9ghFzbxYWx"},"id":"CuPkN6ozW9r_","outputId":"172907dc-bf09-4a37-9c37-944275e909b7"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["\n","#####################################################################################################################\n","#   Neural Network Analysis\n","#   This is a starter code in Python 3.6 for a neural network.\n","#   You need to have numpy and pandas installed before running this code.\n","#   You need to complete all TODO marked sections\n","#   You are free to modify this code in any way you want, but need to mention it\n","#       in the README file.\n","#\n","#####################################################################################################################\n","\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import keras\n","from keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn.metrics import recall_score\n","from matplotlib import pyplot as plt\n","from itertools import product\n","\n","\n","\n","\n","class NeuralNet:\n","    def __init__(self, dataFile, header=True):\n","        self.raw_input = pd.read_csv(dataFile, delim_whitespace = True)\n","\n","    # TODO: Write code for pre-processing the dataset, which would include\n","    # standardization, normalization,\n","    #   categorical to numerical, etc\n","    def preprocess(self):\n","        self.processed_data = self.raw_input\n","        self.processed_data.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'car_name']\n","        self.processed_data = self.processed_data.dropna()\n","        self.processed_data = self.processed_data.drop_duplicates()\n","        self.processed_data = self.processed_data.drop(self.processed_data[self.processed_data['horsepower'] == '?'].index)\n","\n","        self.processed_data[\"cylinders\"] = pd.to_numeric(self.processed_data[\"cylinders\"], downcast=\"integer\")\n","        self.processed_data[\"displacement\"] = pd.to_numeric(self.processed_data[\"displacement\"], downcast=\"float\")\n","        self.processed_data[\"horsepower\"] = pd.to_numeric(self.processed_data[\"horsepower\"], downcast=\"float\")\n","        self.processed_data[\"model_year\"] = pd.to_numeric(self.processed_data[\"model_year\"], downcast=\"integer\")\n","        self.processed_data['weight'] = pd.to_numeric(self.processed_data['weight'], downcast='float')\n","        self.processed_data['origin'] = pd.to_numeric(self.processed_data['origin'], downcast='integer')\n","\n","        self.processed_data = self.processed_data.reset_index(drop=True)\n","\n","        #normalize data\n","        #Y = np.array((Y - Y.mean())/Y.std())\n","        #X = X.apply(lambda rec:(rec-rec.mean())/rec.std(), axis=0)\n","\n","        return 0\n","\n","    # TODO: Train and evaluate models for all combinations of parameters\n","    # specified in the init method. We would like to obtain following outputs:\n","    #   1. Training Accuracy and Error (Loss) for every model\n","    #   2. Test Accuracy and Error (Loss) for every model\n","    #   3. History Curve (Plot of Accuracy against training steps) for all\n","    #       the models in a single plot. The plot should be color coded i.e.\n","    #       different color for each model\n","\n","\n","    def train_evaluate(self):\n","\n","      #X = self.processed_data.drop(\"mpg\", axis = 1)\n","      X = self.processed_data[['weight', 'horsepower', 'displacement', 'cylinders']]\n","      X = X.apply(lambda rec:(rec-rec.mean())/rec.std(), axis=0)\n","      y = self.processed_data['mpg']\n","      y = np.array((y - y.mean())/y.std())\n","      y = pd.DataFrame(y, columns=['mpg'])\n","      y=y['mpg']\n","      y = to_categorical(y)\n","\n","      X_train, X_test, y_train, y_test = train_test_split(\n","          X, y)\n","\n","      # hyperparameters to use for model evaluation\n","      activations = ['sigmoid', 'tanh', 'relu']\n","      learning_rate = [0.01, 0.1]\n","      max_iterations = [100, 200] # also known as epochs\n","      num_hidden_layers = [2, 3]\n","\n","      possible_params = list(product(activations, learning_rate, max_iterations, num_hidden_layers))\n","\n","      # go through each possible case\n","      model_histories = []\n","      trial = 1\n","      combos = []\n","      for combo in possible_params:\n","        act, alpha, epoch, layers = combo\n","\n","        # add the layers with current activation\n","        model = Sequential()\n","\n","        if layers == 2:\n","          model.add(Dense(800, activation=act))\n","        elif layers == 3:\n","          model.add(Dense(800, activation=act))\n","          model.add(Dense(500, activation=act))\n","\n","        model.add(Dense(500, activation=act, input_dim=8))\n","        model.add(Dense(3, activation='softmax'))\n","\n","        # learning rate\n","        opt = keras.optimizers.Adam(learning_rate=alpha)\n","\n","        model.compile(optimizer=opt,\n","          loss='categorical_crossentropy',\n","          metrics=['accuracy'])\n","\n","    # output the accuracy, error, and hyperparameters used for each trial\n","        print(f'\\n____________________________________________TRIAL #{trial} is currently loading...____________________________________________')\n","        model.fit(X_train, y_train)\n","        outp = model.evaluate(X_train, y_train, verbose=0)\n","        train_accuracy = outp[1]\n","        train_error = 1 - outp[1]\n","\n","        y_test_pred = model.predict(X_test)\n","        outp2 = model.evaluate(X_test, y_test, verbose=0)\n","        test_accuracy = outp2[1]\n","        test_error = 1 - outp2[1]\n","\n","        # track model history and combination of hyperparameters used\n","        history = model.fit(X_train, y_train, epochs=epoch, batch_size=4, verbose=0, validation_data=(X_test,y_test))\n","        model_histories.append(history)\n","        combos.append({\n","            'Trial Number': trial,\n","            'Learning Rate': alpha,\n","            'Activation Function': act,\n","            'Epochs': epoch,\n","            'Number of Layers': layers,\n","            'Train Accuracy': train_accuracy,\n","            'Train Error': train_error,\n","            'Test Accuracy': test_accuracy,\n","            'Test Error': test_error\n","        })\n","\n","        trial += 1\n","\n","      # SHOWING THE TABLE\n","      output = pd.DataFrame(columns = ['Trial Number', 'Learning Rate', 'Activation Function', 'Epochs', 'Number of Layers', 'Train Accuracy', 'Train Error', 'Test Accuracy', 'Test Error'])\n","\n","      # PLOTTING THE HISTORY\n","\n","      plt.figure(figsize=(35,35))\n","      i = 0\n","\n","      for combo in combos:\n","        output = output.append(combo, ignore_index = True)\n","        trial_num = combo['Trial Number']\n","        epoch = combo['Epochs']\n","        plt.plot(model_histories[i].history['accuracy'], label = f'Trial: {trial_num}, Epochs: {epoch}')\n","        i = i + 1\n","\n","      plt.title('Model Accuracy')\n","      plt.ylabel('Accuracy')\n","      plt.xlabel('Epochs')\n","      plt.legend()\n","      plt.show()\n","      display(output)\n","\n","      return 0\n","\n","\n","if __name__ == \"__main__\":\n","    neural_network = NeuralNet(\"https://raw.githubusercontent.com/Jerpac/CS4375/main/auto-mpg.data\") # put in path to your file\n","    neural_network.preprocess()\n","    neural_network.train_evaluate()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FbWPRmujlnc6"},"outputs":[],"source":[]}],"metadata":{"accelerator":"TPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}